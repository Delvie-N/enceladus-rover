This code was written by an individual MSc Space Engineering student at the Delft University of Technology. 

For the course AE4350 'Bio-inspired Intelligence and Learning for Aerospace Applications', I created a Reinforcement Learning model based on a Deep Q-Learning Network with $\epsilon$-greedy policy and following an Action-based training method that could assist a rover in autonomously navigating the unknown environment of the Enceladan surface. 

The aim of this project is to showcase how Reinforcement Learning could help a rover autonomously navigate the unknown icy environment of the Enceladan surface. Due to the complexity and low speed of deep space communications, combined with the little Enceladan surface mapping having been performed in the past, the environment is effectively unknown and the rover must navigate autonomously depending on what environment it senses upon arrival. This can be modelled simply by randomly generating a world with obstacles, representing the icy ridges in the Enceladan surface, around which the rover has to navigate from a start to an end point. Throughout its journey it must then visit the plume vents for directly sampling of the materials present as well as analysing the vent mechanisms. Then teaching the model through RL whilst randomising both obstacle and plume locations and sizes, allows the rover to navigate effectively.